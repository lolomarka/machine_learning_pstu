# Лабораторная работа №6. Локальные большие языковые модели

1. Необходимо развернуть локальную языковую модель и протестировать ее.
2. Для этого нужно создать виртуальную среду  `python -m venv ./venv` во избежание конфликта с уже установленными версиями пакетов в системе
3. Изучить туториал по llama.cpp: [Run LLMs on Your CPU with Llama.cpp: A Step-by-Step Guide](https://awinml.github.io/llm-ggml-python/)
4. Воспользовавшись либо моделью из примера, либо любой другой моделью, например [TheBloke/Mistral-7B-Instruct-v0.2-GGUF at main](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/tree/main), решить ряд задач:
    1. Попросить модель пересказать для ребенка содержание эссе [The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html) на английском языке
    2. Попросить перевести указанное эссе на русский язык, оценить перевод
    3. Самостоятельно сделать краткий пересказ любой из статей из научного журнала «Вестник ПНИПУ. Электротехника, информационные технологии, системы управления» за 2023 год
    4. Попросить модель сделать краткий пересказ той же самой статьи
    5. Попросить другого человека прочесть статью и оценить пересказы по шкале от 0 до 10

>[!note]
>Смысл именно в том, чтобы оценить способности модели про продуцированию текста относительно человека. Поэтому не надо заниматься читерством — важно не то, насколько подробно вы перескажете ту или иную статью, а то, что вы это сделаете сами, будучи человеком.
>